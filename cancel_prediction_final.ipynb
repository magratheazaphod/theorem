{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib notebook\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.components.connected import connected_components\n",
    "\n",
    "#show up to 100 columns.\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file = \"new_theorem_data.p\"\n",
    "\n",
    "## data appears to have been savied in Python 2 - changing encoding allows us to properly load data\n",
    "with open(data_file, 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of rows:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3dbfd389ab4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "cols = data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of columns:',len(cols),cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bc0b0d5f8302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## 86 different categories - start by taking correlation matrix to figure out which categories are redundant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Draw the heatmap using seaborn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "## 86 different categories - start by taking correlation matrix to figure out which categories are redundant\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "# Draw the heatmap using seaborn\n",
    "sns.heatmap(corr, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## thank you to stack overflow for the elegant solution: \n",
    "## http://stackoverflow.com/questions/4842613/merge-lists-that-share-common-elements\n",
    "def to_graph(l):\n",
    "    G = nx.Graph()\n",
    "    for part in l:\n",
    "        G.add_nodes_from(part)\n",
    "        G.add_edges_from(to_edges(part))\n",
    "    return G\n",
    "\n",
    "def to_edges(l):\n",
    "    \"\"\" \n",
    "        treat `l` as a Graph and returns it's edges \n",
    "        to_edges(['a','b','c','d']) -> [(a,b), (b,c),(c,d)]\n",
    "    \"\"\"\n",
    "    it = iter(l)\n",
    "    last = next(it)\n",
    "\n",
    "    for current in it:\n",
    "        yield last, current\n",
    "        last = current    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cutoff of .6 recovers 47 inter-connected variables, .5 recovers 52, .55 recovers 50\n",
    "## cutoff of .55 features largest group at length 10 - probably don't want to exceed that\n",
    "tentative_families = []\n",
    "cutoff = .55\n",
    "\n",
    "for name, col in corr.iteritems():\n",
    "    \n",
    "    highly_correlated = (abs(col) > cutoff) & (col.index != name)\n",
    "    high_corr_list = col[highly_correlated].index.tolist()\n",
    "    \n",
    "    if high_corr_list != []:\n",
    "        tentative_families.append(sorted(high_corr_list + [ name ]))\n",
    "        \n",
    "tentative_families.sort()\n",
    "tentative_families = list(tentative_families for tentative_families,_ in itertools.groupby(tentative_families))\n",
    "\n",
    "for fam in sorted(tentative_families):\n",
    "    print(fam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = to_graph(tentative_families)\n",
    "cc = nx.connected_components(G)\n",
    "families = []\n",
    "\n",
    "for nodes in cc:\n",
    "    families.append(list(nodes))\n",
    "    \n",
    "families = sorted([ sorted(fam) for fam in families ])\n",
    "    \n",
    "for fam in families:\n",
    "    print(fam, len(fam))\n",
    "    \n",
    "ll = [ len(fam) for fam in families ]\n",
    "print(sum(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## give custom descriptive names to each family\n",
    "# two items: first, each unit in the family; second, the variable(s) you're going to keep around.\n",
    "family_dict = {}\n",
    "family_dict['fractional_loan'] = [families[0],'BoolEverWholeLoan']\n",
    "family_dict['debt'] = [families[1],'DolMonthlyDebt']\n",
    "family_dict['borrower_rate'] = [families[2],'BorrowerRate']\n",
    "family_dict['loan_amount'] = [families[3],'DolLoanAmountRequested']\n",
    "family_dict['prosper_history'] = [families[4],'DolPriorProsperLoansPrincipalBorrowed']\n",
    "family_dict['revolving_balance'] = [families[5],'DolTotalBalanceOpenRevolving6']\n",
    "family_dict['credit'] = [families[6],'NumCurrentCreditLines']\n",
    "family_dict['delinquencies'] = [families[7],'PctTradesNeverDelinquent']\n",
    "family_dict['inquiries'] = [families[8],'NumTotalInquiries']\n",
    "family_dict['prior_prosper_loans'] = [families[9],'NumPriorProsperLoans61dpd']\n",
    "family_dict['real_estate'] = [families[10],'NumRealEstateTrades']\n",
    "family_dict['current_delinquency'] = [families[11],'NumTradesCurr30DPDOrDerog6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create reduced data set by dropping headers...\n",
    "reduced_data = pd.DataFrame.copy(data, deep = True)\n",
    "\n",
    "## immediately drop columns that are unlikely/unable to cause loan cancellation (ID numbers/dates)\n",
    "drop_cols = ['ListingID', 'DateCreditPulled', 'DateListingStart', 'DateListingCreation', 'DateWholeLoanStart', 'DateWholeLoanEnd']\n",
    "reduced_data.drop(drop_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## drop similar columns as determined by families\n",
    "for fam, items in family_dict.items():\n",
    "    drop_cols = list(items[0])\n",
    "    drop_cols.remove(items[1]) #keep our chosen representative variable for that family\n",
    "    reduced_data.drop(drop_cols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_names = reduced_data.columns.values\n",
    "print(len(reduced_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduced_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ecb1efbfae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## manually drop a few other columns that won't help our analysis...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreduced_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StrState'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'StrBorrowerCity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BoolIncomeVerifiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reduced_data' is not defined"
     ]
    }
   ],
   "source": [
    "## manually drop a few other columns that won't help our analysis...\n",
    "reduced_data.drop(['StrState','StrBorrowerCity','BoolIncomeVerifiable'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk.linear_model.logistic_regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
